{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. PREPROCESSING\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('adaKami-reviews.csv', index_col=0)\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('indonesian') + stopwords.words('english'))\n",
        "custom_stopwords = {'yang', 'di', 'ke', 'dari', 'untuk', 'ini', 'itu', 'dengan', 'dan', 'atau', 'pada'}\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "df['processed_review'] = df['cleaned_review'].apply(remove_stopwords)\n",
        "\n",
        "# Remove empty reviews\n",
        "df = df[df['processed_review'].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nAfter preprocessing: {len(df)} reviews\")\n",
        "print(f\"\\nSample processed reviews:\")\n",
        "print(df[['review', 'processed_review']].head())\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=2, max_df=0.8)\n",
        "X = vectorizer.fit_transform(df['processed_review'])\n",
        "\n",
        "print(f\"\\nTF-IDF matrix shape: {X.shape}\")\n",
        "print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. WORDCLOUD\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Combine all processed reviews into one text\n",
        "all_text = ' '.join(df['processed_review'])\n",
        "\n",
        "# Generate WordCloud\n",
        "wordcloud = WordCloud(width=1200, height=600, \n",
        "                      background_color='white',\n",
        "                      colormap='viridis',\n",
        "                      max_words=100,\n",
        "                      relative_scaling=0.5,\n",
        "                      min_font_size=10).generate(all_text)\n",
        "\n",
        "# Display WordCloud\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud - AdaKami Reviews', fontsize=20, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top 20 most frequent words\n",
        "from collections import Counter\n",
        "words = all_text.split()\n",
        "word_freq = Counter(words).most_common(20)\n",
        "\n",
        "print(\"\\nTop 20 Most Frequent Words:\")\n",
        "for word, freq in word_freq:\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. CLUSTERING\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Calculate inertia for elbow method (k from 2 to 10)\n",
        "inertias = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "print(\"Training K-Means models...\")\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)\n",
        "    kmeans.fit(X)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    print(f\"K={k}: Inertia = {kmeans.inertia_:.2f}\")\n",
        "\n",
        "# Perform clustering with optimal k (let's use k=4 as default)\n",
        "optimal_k = 4\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Performing K-Means Clustering with K={optimal_k}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10, max_iter=300)\n",
        "df['cluster'] = kmeans_final.fit_predict(X)\n",
        "\n",
        "# Display cluster distribution\n",
        "print(f\"\\nCluster Distribution:\")\n",
        "print(df['cluster'].value_counts().sort_index())\n",
        "\n",
        "# Show sample reviews from each cluster\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"Sample Reviews from Each Cluster:\")\n",
        "print(f\"{'='*50}\")\n",
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    print(f\"\\n--- CLUSTER {cluster} ---\")\n",
        "    samples = df[df['cluster'] == cluster].head(3)\n",
        "    for idx, row in samples.iterrows():\n",
        "        print(f\"Review: {row['review'][:150]}...\")\n",
        "        print(f\"Rating: {row['rating']}\")\n",
        "        print()\n",
        "\n",
        "# PCA for visualization (reduce to 2D)\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X.toarray())\n",
        "df['pca1'] = X_pca[:, 0]\n",
        "df['pca2'] = X_pca[:, 1]\n",
        "\n",
        "print(f\"\\nPCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. VISUALISASI (Elbow Method & Cluster Visualization)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (16, 6)\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# --- Plot 1: Elbow Method ---\n",
        "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Elbow Method - Optimal K Selection', fontsize=14, fontweight='bold', pad=15)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xticks(k_range)\n",
        "\n",
        "# Highlight the optimal k\n",
        "axes[0].axvline(x=optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal K = {optimal_k}')\n",
        "axes[0].legend(fontsize=10)\n",
        "\n",
        "# --- Plot 2: Cluster Visualization (2D PCA) ---\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E2']\n",
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    cluster_data = df[df['cluster'] == cluster]\n",
        "    axes[1].scatter(cluster_data['pca1'], cluster_data['pca2'], \n",
        "                   c=colors[cluster % len(colors)], \n",
        "                   label=f'Cluster {cluster}',\n",
        "                   alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "axes[1].set_xlabel('First Principal Component', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Second Principal Component', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(f'K-Means Clustering Visualization (K={optimal_k})', fontsize=14, fontweight='bold', pad=15)\n",
        "axes[1].legend(fontsize=10, loc='best')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Additional: Rating distribution per cluster\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "cluster_rating = df.groupby(['cluster', 'rating']).size().unstack(fill_value=0)\n",
        "cluster_rating.plot(kind='bar', stacked=True, ax=ax, colormap='viridis', width=0.7)\n",
        "ax.set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Rating Distribution per Cluster', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.legend(title='Rating', fontsize=10)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. SILHOUETTE SCORE\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "# Calculate silhouette scores for different K values\n",
        "silhouette_scores = []\n",
        "\n",
        "print(\"Calculating Silhouette Scores for different K values...\")\n",
        "print(\"=\"*60)\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)\n",
        "    cluster_labels = kmeans.fit_predict(X)\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "    print(f\"K={k}: Silhouette Score = {silhouette_avg:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Best K based on Silhouette Score: K={k_range[np.argmax(silhouette_scores)]} \"\n",
        "      f\"(Score: {max(silhouette_scores):.4f})\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Visualize Silhouette Scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Silhouette Score vs K\n",
        "axes[0].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Silhouette Score Analysis', fontsize=14, fontweight='bold', pad=15)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xticks(k_range)\n",
        "axes[0].axhline(y=max(silhouette_scores), color='red', linestyle='--', alpha=0.5, \n",
        "                label=f'Max Score = {max(silhouette_scores):.4f}')\n",
        "axes[0].legend(fontsize=10)\n",
        "\n",
        "# Plot 2: Silhouette Plot for optimal K\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10, max_iter=300)\n",
        "cluster_labels = kmeans.fit_predict(X)\n",
        "silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "y_lower = 10\n",
        "colors = cm.nipy_spectral(cluster_labels.astype(float) / optimal_k)\n",
        "\n",
        "for i in range(optimal_k):\n",
        "    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "    ith_cluster_silhouette_values.sort()\n",
        "    \n",
        "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "    y_upper = y_lower + size_cluster_i\n",
        "    \n",
        "    color = cm.nipy_spectral(float(i) / optimal_k)\n",
        "    axes[1].fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "    \n",
        "    axes[1].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i), fontweight='bold')\n",
        "    y_lower = y_upper + 10\n",
        "\n",
        "axes[1].set_xlabel('Silhouette Coefficient Values', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Cluster Label', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(f'Silhouette Plot for K={optimal_k}\\n(Avg Score: {silhouette_avg:.4f})', \n",
        "                  fontsize=14, fontweight='bold', pad=15)\n",
        "axes[1].axvline(x=silhouette_avg, color='red', linestyle='--', linewidth=2, \n",
        "                label=f'Average Score = {silhouette_avg:.4f}')\n",
        "axes[1].set_yticks([])\n",
        "axes[1].legend(fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nSilhouette Score Summary for K={optimal_k}:\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Average Silhouette Score: {silhouette_avg:.4f}\")\n",
        "print(f\"Min Silhouette Score: {sample_silhouette_values.min():.4f}\")\n",
        "print(f\"Max Silhouette Score: {sample_silhouette_values.max():.4f}\")\n",
        "print(f\"Std Silhouette Score: {sample_silhouette_values.std():.4f}\")\n",
        "print(f\"\\nSilhouette Score per Cluster:\")\n",
        "for i in range(optimal_k):\n",
        "    cluster_silhouette = sample_silhouette_values[cluster_labels == i]\n",
        "    print(f\"  Cluster {i}: {cluster_silhouette.mean():.4f} (size: {len(cluster_silhouette)})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
