{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SENTENCE-BERT - Preprocessing & Generate Embeddings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('adaKami-reviews.csv', index_col=0)\n",
        "df = df[df['review'].notna()].reset_index(drop=True)\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "\n",
        "# Preprocessing RINGAN untuk Sentence-BERT\n",
        "# PENTING: Jangan terlalu agresif! Sentence-BERT butuh konteks kalimat\n",
        "def light_preprocess(text):\n",
        "    \"\"\"\n",
        "    Preprocessing ringan untuk Sentence-BERT:\n",
        "    - Hapus URL, email, mention\n",
        "    - Hapus karakter berlebihan (!!!, ???)\n",
        "    - Normalisasi whitespace\n",
        "    - JANGAN hapus stopwords (penting untuk konteks)\n",
        "    - JANGAN lowercase semua (kapitalisasi bisa penting)\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    \n",
        "    # Remove email\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    \n",
        "    # Remove mentions\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    \n",
        "    # Normalize excessive punctuation (!!!! -> !, ???? -> ?)\n",
        "    text = re.sub(r'[!]{2,}', '!', text)\n",
        "    text = re.sub(r'[?]{2,}', '?', text)\n",
        "    text = re.sub(r'\\.{2,}', '.', text)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "print(\"\\nPreprocessing text...\")\n",
        "df['processed_review'] = df['review'].apply(light_preprocess)\n",
        "\n",
        "# Remove empty reviews\n",
        "df = df[df['processed_review'].str.len() > 10].reset_index(drop=True)\n",
        "print(f\"After preprocessing: {len(df)} reviews\")\n",
        "\n",
        "# Show examples\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONTOH PREPROCESSING:\")\n",
        "print(\"=\"*80)\n",
        "for i in range(min(3, len(df))):\n",
        "    print(f\"\\nORIGINAL:\\n{df['review'].iloc[i][:150]}...\")\n",
        "    print(f\"\\nPROCESSED:\\n{df['processed_review'].iloc[i][:150]}...\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "# Load Sentence-BERT model (multilingual untuk bahasa Indonesia)\n",
        "print(\"\\nLoading Sentence-BERT model...\")\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Generate embeddings dari text yang sudah dipreprocessing\n",
        "print(\"\\nGenerating embeddings from preprocessed text...\")\n",
        "embeddings = model.encode(df['processed_review'].tolist(), show_progress_bar=True, batch_size=32)\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "print(\"\\n✓ Embeddings berhasil dibuat! Lanjut ke cell berikutnya untuk elbow method.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ELBOW METHOD - Mencari Optimal K\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate inertia dan silhouette score untuk berbagai K\n",
        "k_range = range(2, 11)\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "\n",
        "print(\"Menghitung Elbow Method dan Silhouette Score...\")\n",
        "print(\"=\"*60)\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)\n",
        "    labels = kmeans.fit_predict(embeddings)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    sil_score = silhouette_score(embeddings, labels)\n",
        "    silhouette_scores.append(sil_score)\n",
        "    print(f\"K={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={sil_score:.4f}\")\n",
        "\n",
        "# Visualisasi\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Elbow Method\n",
        "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Inertia (WCSS)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Elbow Method - Sentence-BERT Embeddings', fontsize=14, fontweight='bold', pad=15)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xticks(k_range)\n",
        "\n",
        "# Plot 2: Silhouette Score\n",
        "axes[1].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Silhouette Score Analysis', fontsize=14, fontweight='bold', pad=15)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].set_xticks(k_range)\n",
        "best_k = k_range[silhouette_scores.index(max(silhouette_scores))]\n",
        "axes[1].axvline(x=best_k, color='red', linestyle='--', linewidth=2, \n",
        "                label=f'Best K={best_k} (Score={max(silhouette_scores):.4f})')\n",
        "axes[1].legend(fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Rekomendasi K berdasarkan Silhouette Score: K={best_k}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Update clustering dengan K optimal\n",
        "optimal_k = best_k\n",
        "print(f\"\\nMenggunakan K={optimal_k} untuk clustering...\")\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(embeddings)\n",
        "silhouette = silhouette_score(embeddings, df['cluster'])\n",
        "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
        "print(f\"\\nCluster Distribution:\")\n",
        "print(df['cluster'].value_counts().sort_index())\n",
        "\n",
        "# UMAP untuk visualisasi\n",
        "print(\"\\nReducing dimensions with UMAP...\")\n",
        "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "embeddings_2d = reducer.fit_transform(embeddings)\n",
        "df['umap1'] = embeddings_2d[:, 0]\n",
        "df['umap2'] = embeddings_2d[:, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VISUALISASI CLUSTERING\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# Plot 1: Cluster Visualization\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E2']\n",
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    cluster_data = df[df['cluster'] == cluster]\n",
        "    axes[0].scatter(cluster_data['umap1'], cluster_data['umap2'], \n",
        "                   c=colors[cluster % len(colors)], \n",
        "                   label=f'Cluster {cluster} (n={len(cluster_data)})',\n",
        "                   alpha=0.7, s=60, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "axes[0].set_xlabel('UMAP 1', fontsize=13, fontweight='bold')\n",
        "axes[0].set_ylabel('UMAP 2', fontsize=13, fontweight='bold')\n",
        "axes[0].set_title(f'Sentence-BERT Clustering (K={optimal_k})\\nSilhouette Score: {silhouette:.4f}', \n",
        "                  fontsize=15, fontweight='bold', pad=15)\n",
        "axes[0].legend(fontsize=10, loc='best', framealpha=0.9)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Rating Distribution per Cluster\n",
        "cluster_rating = df.groupby(['cluster', 'rating']).size().unstack(fill_value=0)\n",
        "cluster_rating.plot(kind='bar', stacked=True, ax=axes[1], colormap='RdYlGn', width=0.7)\n",
        "axes[1].set_xlabel('Cluster', fontsize=13, fontweight='bold')\n",
        "axes[1].set_ylabel('Count', fontsize=13, fontweight='bold')\n",
        "axes[1].set_title('Rating Distribution per Cluster', fontsize=15, fontweight='bold', pad=15)\n",
        "axes[1].legend(title='Rating', fontsize=10, title_fontsize=11)\n",
        "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sample reviews per cluster\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAMPLE REVIEWS DARI SETIAP CLUSTER:\")\n",
        "print(\"=\"*80)\n",
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"CLUSTER {cluster} - Total: {len(df[df['cluster']==cluster])} reviews\")\n",
        "    print(f\"{'='*80}\")\n",
        "    samples = df[df['cluster'] == cluster].sample(min(3, len(df[df['cluster']==cluster])), random_state=42)\n",
        "    for idx, (i, row) in enumerate(samples.iterrows(), 1):\n",
        "        print(f\"\\n{idx}. Rating: {row['rating']} ⭐\")\n",
        "        print(f\"   Original : {row['review'][:180]}...\")\n",
        "        print(f\"   Processed: {row['processed_review'][:180]}...\")\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
